{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Binary Classification on mnist dataset\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing packages\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 1)\n"
     ]
    }
   ],
   "source": [
    "# loading the training datasets\n",
    "\n",
    "x_traindata = loadmat(\"mnistTrainImages.mat\")\n",
    "y_trainlabels = loadmat(\"mnistTrainLabels.mat\")\n",
    "\n",
    "# Extracting the relevant information from the datasets\n",
    "\n",
    "x_traindata = x_traindata[\"trainData\"]\n",
    "y_trainlabels = y_trainlabels[\"trainLabels\"]\n",
    "\n",
    "print x_traindata.shape\n",
    "print y_trainlabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading the test datasets\n",
    "\n",
    "x_testdata = loadmat(\"mnistTestImages.mat\")\n",
    "y_testlabels = loadmat(\"mnistTestLabels.mat\")\n",
    "\n",
    "# Extracting the relevant information from the datase\n",
    "\n",
    "x_testdata = x_testdata[\"testData\"]\n",
    "y_testlabels = y_testlabels[\"testLabels\"]\n",
    "\n",
    "#print x_testdata.shape\n",
    "#print type(y_testlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# converting the list of lists to a numpy array\n",
    "\n",
    "y_trainlabels = [i[0] for i in y_trainlabels]\n",
    "y_trainlabels = np.array(y_trainlabels)\n",
    "print y_trainlabels.shape\n",
    "\n",
    "y_testlabels = [i[0] for i in y_testlabels]\n",
    "y_testlabels = np.array(y_testlabels)\n",
    "print y_testlabels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n"
     ]
    }
   ],
   "source": [
    "# Inserting a column of ones for both training and test data\n",
    "\n",
    "x_traindata = np.insert(x_traindata,0,1,axis=1)\n",
    "x_testdata = np.insert(x_testdata,0,1,axis=1)\n",
    "\n",
    "print x_traindata.shape\n",
    "#print x_testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n",
      "(785,)\n"
     ]
    }
   ],
   "source": [
    "# Initializing the parameters\n",
    "\n",
    "theta = np.ones(x_traindata[0].shape)\n",
    "oldtheta = np.inf\n",
    "alpha = 0.05\n",
    "epsilon = 15\n",
    "#print theta\n",
    "print oldtheta\n",
    "print theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logit(x,theta_calc):\n",
    "    return 1/(1+(np.exp(-(np.matmul(theta_calc,np.transpose(x))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss_fun(x,theta_calc,y):\n",
    "    return np.matmul(np.transpose(x),(logit(x,theta_calc)-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gradient_descent(learn_rate,tolerance,theta_calc,old_theta_calc,x,y):\n",
    "    iteration = 0\n",
    "    while(np.linalg.norm(theta_calc - old_theta_calc, ord=2) > tolerance):\n",
    "        iteration = iteration+1\n",
    "        old_theta_calc = theta_calc\n",
    "        theta_calc = old_theta_calc - learn_rate*calc_loss_fun(x,theta_calc,y)\n",
    "    return (theta_calc,iteration)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmacs/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785,)\n",
      "\n",
      " Iteration =  239\n"
     ]
    }
   ],
   "source": [
    "(theta,iteration) = Gradient_descent(alpha,epsilon,theta,oldtheta,x_traindata,y_trainlabels)\n",
    "print theta.shape\n",
    "print \"\\n Iteration = \", iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmacs/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "prediction = logit(x_testdata,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Assigning Labels \n",
    "\n",
    "cutoff = 0.5\n",
    "for i in range(prediction.size):\n",
    "    if prediction[i] >= cutoff:\n",
    "        prediction[i] = 1\n",
    "    else:\n",
    "        prediction[i] = 0\n",
    "print prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.9907\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy\n",
    "\n",
    "correct_prediction = 0\n",
    "for i in range(y_testlabels.size):\n",
    "    if prediction[i] == y_testlabels[i]:\n",
    "        correct_prediction = correct_prediction +1\n",
    "print \"Accuracy is \", correct_prediction/float(y_testlabels.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Observation - \n",
    "\n",
    "\n",
    "| Alpha(Learning_Rate) | Epsilon(Error_tollerance) | No._of_iteration | Accuracy |\n",
    "| :--------: | :-------: | :---------: | :-------:|\n",
    "| | | | |\n",
    "| 0.1 | 30 | 239 | 99.07 |\n",
    "| 0.1 | 20 | 387 | 99.12 |\n",
    "| 0.1 | 15 | 1835 | 99.11 |\n",
    "| | | | |\n",
    "| 0.05 | 30 |107 | 99.02 |\n",
    "| 0.05| 20 | 177 | 99.01 |\n",
    "| 0.05 | 15 | 239 | 99.07 |\n",
    "| | | | |\n",
    "| 0.01 | 30 | 14 | 97.61 |\n",
    "| 0.01 | 20 | 27 | 98.17 |\n",
    "| 0.01 | 15 | 38 | 98.38 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though for learning rate 0.1 and error tollerance 15 we got a very good accuracy of 99.11 the number of iteration it took is almost 7 times more than the number of iteration it took for learning rate 0.05 with error tollerance 15 giving a close accuracy of 99.07."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also interesting to note that we got same accuracy i.e 99.07 for learning rate 0.1 and error tollerance 30 and for learning rate 0.05 and error tollerance 15. Both of these took same number of iteration i.e 239. Given a choice to pick between one of the two configuration, we must pick the one with least error tollerance in such case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also observe a very slight oscillation in accuracy when error tollerance is changed from 20 to 15 in case of learning rate 0.1 and when error rate was changed from 30 to 20 in case of learning rate 0.05. In both these cases the number of iteration increased but the accuracy decreased."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
